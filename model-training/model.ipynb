{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f893102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50648b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4413c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total A Paths: 1067\n",
      "Total B Paths: 1334\n"
     ]
    }
   ],
   "source": [
    "A_path = \"data/trainA\"\n",
    "B_path = \"data/trainB\"\n",
    "\n",
    "A_paths_join = [os.path.join(A_path, f) for f in os.listdir(A_path) if f.endswith(\".jpg\")]\n",
    "B_paths_join = [os.path.join(B_path, f) for f in os.listdir(B_path) if f.endswith(\".jpg\")]\n",
    "\n",
    "\n",
    "print(f\"Total A Paths: {len(A_paths_join)}\")\n",
    "print(f\"Total B Paths: {len(B_paths_join)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2283f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 1067/1067 [00:05<00:00, 200.63it/s]\n"
     ]
    }
   ],
   "source": [
    "SIZE = 256\n",
    "\n",
    "# Transform = resize + to tensor + normalize to [0,1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor(),   # (H,W,C) → (C,H,W) + /255 automatically\n",
    "])\n",
    "\n",
    "horse_images = torch.zeros(len(A_paths_join), 3, SIZE, SIZE)\n",
    "zebra_images = torch.zeros(len(A_paths_join), 3, SIZE, SIZE)\n",
    "\n",
    "for i, (horse_path, zebra_path) in tqdm(enumerate(zip(A_paths_join, B_paths_join)), total=len(A_paths_join), desc=\"Loading\"):\n",
    "    \n",
    "    # Horse\n",
    "    horse_img = Image.open(horse_path).convert(\"RGB\")\n",
    "    horse_tensor = transform(horse_img)    # [3,256,256] float32 0–1\n",
    "    \n",
    "    # Zebra\n",
    "    zebra_img = Image.open(zebra_path).convert(\"RGB\")\n",
    "    zebra_tensor = transform(zebra_img)\n",
    "\n",
    "    horse_images[i] = horse_tensor\n",
    "    zebra_images[i] = zebra_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36d6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = [horse_images, zebra_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af875013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29cd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e29d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, filters, size=3, stride=2, norm=True, activation=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, filters, kernel_size=size, stride=stride, padding=size//2, bias=False)\n",
    "\n",
    "        self.norm = nn.InstanceNorm2d(filters, affine=True) if norm else None\n",
    "\n",
    "        if activation is not None:\n",
    "            self.act = activation\n",
    "        else:\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999d7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, filters, size=3, stride=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convT = nn.ConvTranspose2d(in_channels, filters, kernel_size=size, stride=stride,\n",
    "                                        padding=size//2, output_padding=stride-1, bias=False)\n",
    "\n",
    "        self.norm = nn.InstanceNorm2d(filters, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convT(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ac7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10390f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_resnet=9):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.down1 = Downsample(in_channels, 64, size=7, stride=1)   # 256×256\n",
    "        self.down2 = Downsample(64, 128)                            # 128×128\n",
    "        self.down3 = Downsample(128, 256)                           # 64×64\n",
    "\n",
    "        # 9 ResNet blocks\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *[ResidualBlock(256) for _ in range(n_resnet)]\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = Upsample(256, 128)                               # 128×128\n",
    "        self.up2 = Upsample(128, 64)                                # 256×256\n",
    "\n",
    "        # Output\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "\n",
    "        x = self.resblocks(x)\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7545bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            Downsample(in_channels, 64, size=4, stride=2, norm=False),\n",
    "            Downsample(64, 128, size=4, stride=2),\n",
    "            Downsample(128, 256, size=4, stride=2),\n",
    "            Downsample(256, 512, size=4, stride=2),\n",
    "            Downsample(512, 512, size=4, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)  # PatchGAN\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81b661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineModel(nn.Module):\n",
    "    def __init__(self, g_model1, g_model2, d_model, lr=2e-4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Generator A→B\n",
    "        self.G1 = g_model1\n",
    "        # Generator B→A\n",
    "        self.G2 = g_model2\n",
    "        # Discriminator for B\n",
    "        self.D  = d_model\n",
    "\n",
    "        # Freeze G2 and D\n",
    "        for p in self.G2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.D.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Losses (same as Keras)\n",
    "        self.loss_gan = nn.MSELoss()   # mse\n",
    "        self.loss_l1  = nn.L1Loss()    # mae\n",
    "\n",
    "        self.opt = optim.Adam(self.G1.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    def forward(self, input_gen, input_id):\n",
    "        # Adversarial\n",
    "        gen_1_out = self.G1(input_gen)\n",
    "        dis_out = self.D(gen_1_out)\n",
    "\n",
    "        # Identity\n",
    "        output_id = self.G1(input_id)\n",
    "\n",
    "        # Cycle forward\n",
    "        output_f = self.G2(gen_1_out)\n",
    "\n",
    "        # Cycle backward\n",
    "        gen_2_out = self.G2(input_id)\n",
    "        output_b = self.G1(gen_2_out)\n",
    "\n",
    "        return dis_out, output_id, output_f, output_b\n",
    "\n",
    "    def train_step(self, input_gen, input_id):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "        dis_out, output_id, output_f, output_b = self.forward(input_gen, input_id)\n",
    "\n",
    "        valid = torch.ones_like(dis_out)\n",
    "\n",
    "        # losses exactly like Keras\n",
    "        loss_adv = self.loss_gan(dis_out, valid) * 1\n",
    "        loss_id  = self.loss_l1(output_id, input_id) * 5\n",
    "        loss_fwd = self.loss_l1(output_f, input_gen) * 10\n",
    "        loss_bwd = self.loss_l1(output_b, input_id) * 10\n",
    "\n",
    "        loss = loss_adv + loss_id + loss_fwd + loss_bwd\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "\n",
    "        return {\n",
    "            \"total\": loss.item(),\n",
    "            \"adv\": loss_adv.item(),\n",
    "            \"id\": loss_id.item(),\n",
    "            \"fwd\": loss_fwd.item(),\n",
    "            \"bwd\": loss_bwd.item()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f970f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(n_samples, dataset, device=\"cuda\"):\n",
    "    # Random indices\n",
    "    ix = torch.randint(0, dataset.size(0), (n_samples,), device=dataset.device)\n",
    "\n",
    "    # Select real images\n",
    "    X = dataset[ix]\n",
    "\n",
    "    # Real labels = 1\n",
    "    y = torch.ones((n_samples, 1, 8, 8), device=dataset.device)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def generate_fake_samples(g_model, dataset):\n",
    "    with torch.no_grad():   # same as model.predict()\n",
    "        X = g_model(dataset)\n",
    "\n",
    "    # Fake labels = 0\n",
    "    y = torch.zeros((dataset.size(0), 1, 8, 8), device=dataset.device)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "217bfd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = []\n",
    "\n",
    "    for i in range(images.size(0)):\n",
    "        image = images[i].unsqueeze(0)   # keep batch dim [1,C,H,W]\n",
    "\n",
    "        if len(pool) < max_size:\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "\n",
    "        elif random.random() < 0.5:\n",
    "            selected.append(image)\n",
    "\n",
    "        else:\n",
    "            ix = random.randint(0, len(pool) - 1)\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "\n",
    "    return torch.cat(selected, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fccd7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_preds(g_AB, g_BA, n_images=1):\n",
    "    g_AB.eval()\n",
    "    g_BA.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_images):\n",
    "\n",
    "            idx = np.random.randint(len(horse_images))\n",
    "            horse = horse_images[idx]     # [C,H,W]\n",
    "            zebra = zebra_images[idx]\n",
    "\n",
    "            # Add batch dimension\n",
    "            horse_in = horse.unsqueeze(0)   # [1,C,H,W]\n",
    "            zebra_in = zebra.unsqueeze(0)\n",
    "\n",
    "            # Generate\n",
    "            zebra_pred = g_AB(horse_in)[0]\n",
    "            horse_pred = g_BA(zebra_in)[0]\n",
    "\n",
    "            plt.figure(figsize=(10,8))\n",
    "\n",
    "            plt.subplot(1,4,1)\n",
    "            show_image(horse, title='Original Horse')\n",
    "\n",
    "            plt.subplot(1,4,2)\n",
    "            show_image(zebra_pred, title='Generated Zebra')\n",
    "\n",
    "            plt.subplot(1,4,3)\n",
    "            show_image(zebra, title='Original Zebra')\n",
    "\n",
    "            plt.subplot(1,4,4)\n",
    "            show_image(horse_pred, title='Generated Horse')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e8ec0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    d_model_A, d_model_B,\n",
    "    gen_AB, gen_BA,\n",
    "    opt_g, opt_dA, opt_dB,\n",
    "    trainA, trainB,\n",
    "    epochs=100, chunk=5,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "\n",
    "    mse = torch.nn.MSELoss()\n",
    "    l1  = torch.nn.L1Loss()\n",
    "\n",
    "    poolA, poolB = [], []\n",
    "\n",
    "    n_batch = 1\n",
    "    bat_per_epoch = len(trainA)\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1), desc=\"Epochs\"):\n",
    "\n",
    "        for i in range(bat_per_epoch):\n",
    "\n",
    "            # -----------------------\n",
    "            #  Real samples\n",
    "            # -----------------------\n",
    "            X_realA, y_realA = generate_real_samples(n_batch, trainA)\n",
    "            X_realB, y_realB = generate_real_samples(n_batch, trainB)\n",
    "\n",
    "            X_realA = X_realA.to(device)\n",
    "            X_realB = X_realB.to(device)\n",
    "            y_realA = y_realA.to(device)\n",
    "            y_realB = y_realB.to(device)\n",
    "\n",
    "            # -----------------------\n",
    "            #  Generate fake images\n",
    "            # -----------------------\n",
    "            X_fakeA, y_fakeA = generate_fake_samples(gen_BA, X_realB)\n",
    "            X_fakeB, y_fakeB = generate_fake_samples(gen_AB, X_realA)\n",
    "\n",
    "            X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "            X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "\n",
    "            # -----------------------\n",
    "            #  Train Generator BA\n",
    "            # -----------------------\n",
    "            opt_g.zero_grad()\n",
    "\n",
    "            fakeA = gen_BA(X_realB)\n",
    "            pred_fake = d_model_A(fakeA)\n",
    "            adv_loss = mse(pred_fake, y_realA)\n",
    "\n",
    "            # identity\n",
    "            idA = gen_BA(X_realA)\n",
    "            id_loss = l1(idA, X_realA) * 5\n",
    "\n",
    "            # cycle\n",
    "            recB = gen_AB(fakeA)\n",
    "            cycle_loss = l1(recB, X_realB) * 10\n",
    "\n",
    "            # backward cycle\n",
    "            fakeB = gen_AB(X_realA)\n",
    "            recA = gen_BA(fakeB)\n",
    "            back_loss = l1(recA, X_realA) * 10\n",
    "\n",
    "            gen_loss_BA = adv_loss + id_loss + cycle_loss + back_loss\n",
    "            gen_loss_BA.backward()\n",
    "            opt_g.step()\n",
    "\n",
    "            # -----------------------\n",
    "            #  Train Discriminator A\n",
    "            # -----------------------\n",
    "            opt_dA.zero_grad()\n",
    "            loss_real = mse(d_model_A(X_realA), y_realA)\n",
    "            loss_fake = mse(d_model_A(X_fakeA.detach()), y_fakeA)\n",
    "            dA_loss = (loss_real + loss_fake) * 0.5\n",
    "            dA_loss.backward()\n",
    "            opt_dA.step()\n",
    "\n",
    "            # -----------------------\n",
    "            #  Train Generator AB\n",
    "            # -----------------------\n",
    "            opt_g.zero_grad()\n",
    "\n",
    "            fakeB = gen_AB(X_realA)\n",
    "            pred_fake = d_model_B(fakeB)\n",
    "            adv_loss = mse(pred_fake, y_realB)\n",
    "\n",
    "            idB = gen_AB(X_realB)\n",
    "            id_loss = l1(idB, X_realB) * 5\n",
    "\n",
    "            recA = gen_BA(fakeB)\n",
    "            cycle_loss = l1(recA, X_realA) * 10\n",
    "\n",
    "            fakeA = gen_BA(X_realB)\n",
    "            recB = gen_AB(fakeA)\n",
    "            back_loss = l1(recB, X_realB) * 10\n",
    "\n",
    "            gen_loss_AB = adv_loss + id_loss + cycle_loss + back_loss\n",
    "            gen_loss_AB.backward()\n",
    "            opt_g.step()\n",
    "\n",
    "            # -----------------------\n",
    "            #  Train Discriminator B\n",
    "            # -----------------------\n",
    "            opt_dB.zero_grad()\n",
    "            loss_real = mse(d_model_B(X_realB), y_realB)\n",
    "            loss_fake = mse(d_model_B(X_fakeB.detach()), y_fakeB)\n",
    "            dB_loss = (loss_real + loss_fake) * 0.5\n",
    "            dB_loss.backward()\n",
    "            opt_dB.step()\n",
    "\n",
    "        # -------------------------------------\n",
    "        #  Visualization & Save\n",
    "        # -------------------------------------\n",
    "        if epoch % chunk == 0:\n",
    "            show_preds(gen_AB, gen_BA, n_images=1)\n",
    "            torch.save(gen_AB.state_dict(), \"GeneratorHtoZ.pt\")\n",
    "            torch.save(gen_BA.state_dict(), \"GeneratorZtoH.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "134c19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Generators\n",
    "g_AB = Generator().to(device)   # Horse → Zebra\n",
    "g_BA = Generator().to(device)   # Zebra → Horse\n",
    "\n",
    "# Discriminators\n",
    "d_A = Discriminator().to(device)   # Judge Horses\n",
    "d_B = Discriminator().to(device)   # Judge Zebras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "706db4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "beta1 = 0.5\n",
    "\n",
    "opt_g  = optim.Adam(\n",
    "    list(g_AB.parameters()) + list(g_BA.parameters()),\n",
    "    lr=lr, betas=(beta1, 0.999)\n",
    ")\n",
    "\n",
    "opt_dA = optim.Adam(d_A.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "opt_dB = optim.Adam(d_B.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "551fb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainA = horse_images.to(device)   # [N,3,256,256]\n",
    "trainB = zebra_images.to(device)   # [N,3,256,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7449ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/10 [12:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model_A\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_A\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model_B\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_B\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_AB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_AB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_BA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_BA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_g\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_dA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_dA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_dB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_dB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(d_model_A, d_model_B, gen_AB, gen_BA, opt_g, opt_dA, opt_dB, trainA, trainB, epochs, chunk, device)\u001b[0m\n\u001b[0;32m     62\u001b[0m back_loss \u001b[38;5;241m=\u001b[39m l1(recA, X_realA) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     64\u001b[0m gen_loss_BA \u001b[38;5;241m=\u001b[39m adv_loss \u001b[38;5;241m+\u001b[39m id_loss \u001b[38;5;241m+\u001b[39m cycle_loss \u001b[38;5;241m+\u001b[39m back_loss\n\u001b[1;32m---> 65\u001b[0m \u001b[43mgen_loss_BA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m opt_g\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#  Train Discriminator A\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BM MONEY\\miniconda3\\envs\\hugging\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BM MONEY\\miniconda3\\envs\\hugging\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BM MONEY\\miniconda3\\envs\\hugging\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    d_model_A=d_A,\n",
    "    d_model_B=d_B,\n",
    "    gen_AB=g_AB,\n",
    "    gen_BA=g_BA,\n",
    "    opt_g=opt_g,\n",
    "    opt_dA=opt_dA,\n",
    "    opt_dB=opt_dB,\n",
    "    trainA=trainA,\n",
    "    trainB=trainB,\n",
    "    epochs=10,\n",
    "    chunk=5\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
